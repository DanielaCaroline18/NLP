{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NLP Aula 3- Similaridade de Documentos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "958a46f1f8284b7db48a7c12dcdd1784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_396829386459492697e2a76f7e932195",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2edba051ad534699973665399e5a325f",
              "IPY_MODEL_455d5bfa4ae341ae93eb1cafa24207eb"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "396829386459492697e2a76f7e932195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2edba051ad534699973665399e5a325f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9260b0758e242fc8c5bf5bbfd742561",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d10383c312e465eab6ea68a40cd91fe"
          },
          "model_module_version": "1.5.0"
        },
        "455d5bfa4ae341ae93eb1cafa24207eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c25cdf2163c408593ebc2316a19ed52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [00:38&lt;00:00, 1293.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5aec3eb82ab64523ace67eab0e86ce5a"
          },
          "model_module_version": "1.5.0"
        },
        "f9260b0758e242fc8c5bf5bbfd742561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "9d10383c312e465eab6ea68a40cd91fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "6c25cdf2163c408593ebc2316a19ed52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "5aec3eb82ab64523ace67eab0e86ce5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "374f5c43e51e4b0cad269568388dc8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_500a28ce756c43e6ba3784601716ff8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb037533c9e44ad8bd4edbebdd15586c",
              "IPY_MODEL_edd0523655fc4b53817fcbfc9160a8cb"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "500a28ce756c43e6ba3784601716ff8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "fb037533c9e44ad8bd4edbebdd15586c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5117b75e08240afa707ccf12b5f4200",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdb80f5764bd4098a8b71be3320a2b76"
          },
          "model_module_version": "1.5.0"
        },
        "edd0523655fc4b53817fcbfc9160a8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf349b8892274da0b63cc513d8a81190",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [00:39&lt;00:00, 1239.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d84ba189c2bd4badb59ad10d5c4abd79"
          },
          "model_module_version": "1.5.0"
        },
        "e5117b75e08240afa707ccf12b5f4200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "cdb80f5764bd4098a8b71be3320a2b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cf349b8892274da0b63cc513d8a81190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d84ba189c2bd4badb59ad10d5c4abd79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "e08b555c080c4ce59db8d8cad44b2320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02ba2b17bddd49d0a99bcb0c0a4e8023",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec058f4655b94c72b853a9ca7a2d6c98",
              "IPY_MODEL_091a06981f744042ade057243bc7dae3"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "02ba2b17bddd49d0a99bcb0c0a4e8023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "ec058f4655b94c72b853a9ca7a2d6c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_beb01e82803f4919a14a62e10a278063",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a37d04943278435f88d960b9f8deab79"
          },
          "model_module_version": "1.5.0"
        },
        "091a06981f744042ade057243bc7dae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e4a85941a1a45078ca17848e6ef3b25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [00:17&lt;00:00, 2785.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c23c9597eac6438e91456c3019e8a8f2"
          },
          "model_module_version": "1.5.0"
        },
        "beb01e82803f4919a14a62e10a278063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a37d04943278435f88d960b9f8deab79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5e4a85941a1a45078ca17848e6ef3b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "c23c9597eac6438e91456c3019e8a8f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielaCaroline18/NLP/blob/main/NLP_Aula_3_Similaridade_de_Documentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Mgum7LZZmf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "f86d65ec-2bc2-4d04-dcc3-3fd1ba501e9a"
      },
      "source": [
        "!pip install afinn\n",
        "!python -m textblob.download_corpora\n",
        "!pip install -U textblob\n",
        "!pip install vaderSentiment\n",
        "!pip install pyemd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53452 sha256=cc9d6c2a57522587ecfc45f00fd3f970ad7065cc73bc019489b97eaf8b8516db\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Requirement already satisfied: pyemd in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyemd) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfrtevpOOzfk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4bff480e-6f47-4f5d-eae6-6672ce3eb92e"
      },
      "source": [
        "pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9dcTSYZZml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "57cacafb-71a9-4e55-8ac5-857c6f7659c4"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import gensim\n",
        "import warnings\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "tqdm_notebook.pandas()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjOYV0cfZZmq"
      },
      "source": [
        "# Carregando os embeddings\n",
        "\n",
        "Aqui vamos utilizar os embeddings para realizar as seguintes atividades:\n",
        "\n",
        "- análise de simlaridade\n",
        "- classificação de documentos\n",
        "\n",
        "<b> Carregue os embeddings treinados, como vimos na Aula 2. É o mesmo arquivo que iremos utilizar</b>\n",
        "\n",
        "Link: https://drive.google.com/open?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqMDMgrBZZmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71528c9c-4613-4a4d-85c1-20966c8ab0b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER7E60LF_KHq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae506f25-0067-471c-8b5f-f2441d384150"
      },
      "source": [
        "%%time\n",
        "newfilepath = \"/content/drive/My Drive/embedding_wiki_100d_pt.txt\"\n",
        "filepath = \"/content/drive/My Drive/ptwiki_20180420_100d.txt.bz2\"\n",
        "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
        "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
        "        new_file.write(data)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 42.3 s, sys: 1.07 s, total: 43.3 s\n",
            "Wall time: 46.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2J7vuFY_bI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a248924a-9a24-4236-8e77-411ed2c7aed5"
      },
      "source": [
        "%%time\n",
        "# carregar\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(newfilepath, binary=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 46s, sys: 1.8 s, total: 1min 48s\n",
            "Wall time: 1min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqZJuktuZZmv"
      },
      "source": [
        "# Similaridade de Documentos\n",
        "\n",
        "Para realizar a similaridade entre documentos, utilize as frases abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-YjfkcTZZmw"
      },
      "source": [
        "frase1 = \"Excelente produto chegou antes do prazo indico e recomendo produto bom pois já testei e foi mais que aprovado\" \n",
        "frase2 = \"SUPER RECOMENDO, PREÇO, QUALIDADE #BRASTEMP, EFICIÊNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\"\n",
        "frase3 = \"A tampa do fogão veio com problemas com o pino de encaixe solto e precisa de reparos\"\n",
        "frase4 = \"Fogão ótimo!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGfjS5RZZm1"
      },
      "source": [
        "## Distância de Jaccard\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "1) Faça um método que calcule a similaridade de Jaccard e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: lembrando que você precisa aplicar um pre-processamento nessas frases antes de aplicar o método.\n",
        "Faça:\n",
        "\n",
        "- Lower\n",
        "- Remoção StopWords\n",
        "- Remoção Pontuação\n",
        "- Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQd4dmoPZ2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "40d4b33e-90c6-4721-8d2c-b7584178eff5"
      },
      "source": [
        " import nltk\n",
        " nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2YYL7bZZm2"
      },
      "source": [
        "def pre_processamento_texto(corpus):\n",
        "    print(\"Documento\")\n",
        "    #tokenizacao\"\n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "    #lowcase\n",
        "    corpus_alt = [t.lower() for t in corpus_alt]\n",
        "    #remove stopwords\n",
        "    portugues_stops = stopwords.words('portuguese')\n",
        "    corpus_alt = [t for t in corpus_alt if t not in portugues_stops]\n",
        "    #remove pontuação\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "   \n",
        "    return corpus_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdq_izViPX0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "556f1e56-c025-4ff1-f089-0d7e01ae81a8"
      },
      "source": [
        "frase1_pre_processada = pre_processamento_texto(frase1) \n",
        "frase2_pre_processada = pre_processamento_texto(frase2) \n",
        "frase3_pre_processada = pre_processamento_texto(frase3) \n",
        "frase4_pre_processada = pre_processamento_texto(frase4) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Documento\n",
            "Documento\n",
            "Documento\n",
            "Documento\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qCetFZhQtAT"
      },
      "source": [
        "intersecao / união"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "693bEKfkQOr1"
      },
      "source": [
        "def jaccard_similarity(f1, f2):\n",
        "  return len(set(f1).intersection(set(f2)))/ len(set(f1).union(set(f2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV-FAABQQUyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "19ef7614-e8ff-4e4c-d956-383b9f58e5c9"
      },
      "source": [
        "print (\"Frase 1 e Frase 2\",jaccard_similarity(frase1_pre_processada, frase2_pre_processada) )\n",
        "print (\"Frase 1 e Frase 3\",jaccard_similarity(frase1_pre_processada, frase3_pre_processada) )\n",
        "print (\"Frase 2 e Frase 3\",jaccard_similarity(frase2_pre_processada, frase4_pre_processada) )\n",
        "print (\"Frase 1 e Frase 4\",jaccard_similarity(frase1_pre_processada, frase3_pre_processada) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase 1 e Frase 2 0.10526315789473684\n",
            "Frase 1 e Frase 3 0.0\n",
            "Frase 2 e Frase 3 0.0\n",
            "Frase 1 e Frase 4 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke1PVggcZZm8"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "2) Qual par de frase teve maior simlaridade? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g7wRRl_ZZm9"
      },
      "source": [
        "O par de dados que teve maior similaridade foram as frases 1 e 2. Isso faz sentido pois ambas as frases elogiam o produto e o recomendam . Os pares 1 e 3, e 2 e 3 tiveram similaridade 0, faz sentido pois enquanto em uma das frases o produto é elogiado e recomendado, na outra são levantados alguns defeitos do produto. Já em relação ao par 1 e 4, apesar de ambas falar bem o resultado foi 0, isso se deve ao fato de as frases não conterem palavras iguais e, portanto, a interseção entre elas é nula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND3usAELZZm-"
      },
      "source": [
        "## Distância de Cosseno\n",
        "\n",
        "Aqui iremos calcular a distância do cosseno utilizando duas formas, que aprendemos na aula passada, para representar o texto.\n",
        "\n",
        "- Bag of Words (BOW) \n",
        "- Embedding\n",
        "\n",
        "Observação:\n",
        "\n",
        "Existem duas formas de trabalhar com o cosseno:\n",
        "\n",
        "<b> Distância </b>: quanto menor mais perto estão as frases.\n",
        "<b> Similaridade </b>: quanto maior mais perto estão as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Qw93ZLZZm-"
      },
      "source": [
        "### BOW - Distância do cosseno\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "3) Calcule a distância do cosseno utilizando a representação CountVectorizer e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: no CountVectorizer utilizem as frases já pre-processadas da atividade anterior. Mas para aplicá-las no fit_transform, cada frase deve ser um string (sem estar tokenizada) dentro de uma lista.\n",
        "\n",
        "```python\n",
        "#exemplo\n",
        "distance.cosine(frase1, frase2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CzqpPPGZZm_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bcf5fa4f-3bcd-4dfa-9f8c-fba6489f7d15"
      },
      "source": [
        "vect_bag = CountVectorizer()\n",
        "vect_bag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCEsLqNExmzP"
      },
      "source": [
        "frases = [' '. join(frase1_pre_processada),\n",
        "                       ' '. join(frase2_pre_processada),\n",
        "                       ' '. join(frase3_pre_processada),\n",
        "                       ' '. join(frase4_pre_processada)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hkg2Bxuxvef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4525854-7795-4c74-ef6d-176a24d67417"
      },
      "source": [
        "len(frases)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ2Po98QTFW8"
      },
      "source": [
        "docs_bag = vect_bag.fit_transform(frases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2EVydH9xMrl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00727bd8-d31d-44b2-d743-9631f8bb7604"
      },
      "source": [
        "docs_bag.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUpmTpwqTmHR"
      },
      "source": [
        "frase_1_bow = docs_bag.todense()[0]\n",
        "frase_2_bow = docs_bag.todense()[1]\n",
        "frase_3_bow = docs_bag.todense()[2]\n",
        "frase_4_bow = docs_bag.todense()[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BxfoYUUULRi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "64202939-1e03-40d8-ded2-0a4bd434c5e8"
      },
      "source": [
        "print (\"Frase 1 e Frase 2\",distance.cosine(frase_1_bow, frase_2_bow) )\n",
        "print (\"Frase 1 e Frase 3\",distance.cosine(frase_1_bow, frase_3_bow) )\n",
        "print (\"Frase 2 e Frase 3\",distance.cosine(frase_2_bow, frase_4_bow) )\n",
        "print (\"Frase 1 e Frase 4\",distance.cosine(frase_1_bow, frase_3_bow) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase 1 e Frase 2 0.8309691490542968\n",
            "Frase 1 e Frase 3 1.0\n",
            "Frase 2 e Frase 3 1.0\n",
            "Frase 1 e Frase 4 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFS1MKzZZnE"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "\n",
        "4) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buNHHZPgZZnF"
      },
      "source": [
        "Da mesma forma do método de Distância de Jaccard o método BOW só encontrou similaridade entre as frases 1 e 2, mas não foi capaz de encontrar similaridade entre as frases 1 e 4 que também é positiva. Portanto, esse assim como a Distância de Jaccard, não foi o melhor meio para se calcular a similaridade entre as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3G4ckzlZZnN"
      },
      "source": [
        "### Embedding - Distância do cosseno\n",
        "\n",
        "Para calcular o embedding de cada uma das frases, utilize o modelo carregado inicialmente. \n",
        "\n",
        "Cada palavra tem um vetor, para formar o embedding da frase tire a média de todos os vetores.\n",
        "\n",
        "Utilize as frases já pre-processadas\n",
        "\n",
        "<b> Atividade </b> \n",
        "\n",
        "5) Calcule a distância do cosseno utilizando a representação Embedding e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRO8RnLgZZnO"
      },
      "source": [
        "def get_embeddings (frase):  \n",
        "   return np.mean(np.array([word_vectors[w] for w in frase if w in word_vectors.vocab]), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj85Y8bVZ0TN"
      },
      "source": [
        "frase_1_embedding = get_embeddings(frase1_pre_processada)\n",
        "frase_2_embedding = get_embeddings(frase2_pre_processada)\n",
        "frase_3_embedding = get_embeddings(frase3_pre_processada)\n",
        "frase_4_embedding = get_embeddings(frase4_pre_processada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsS-jcNRTB4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16fa56d4-39ea-42fb-b041-384b3c0568d7"
      },
      "source": [
        "np.array(frase_1_embedding).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMROq-h5aYTB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ae605ef9-9003-4d7b-fef9-32eea7e99307"
      },
      "source": [
        "print (\"Frase 1 e Frase 2\",distance.cosine(frase_1_embedding, frase_2_embedding) )\n",
        "print (\"Frase 1 e Frase 3\",distance.cosine(frase_1_embedding, frase_3_embedding) )\n",
        "print (\"Frase 2 e Frase 3\",distance.cosine(frase_2_embedding, frase_3_embedding) )\n",
        "print (\"Frase 1 e Frase 4\",distance.cosine(frase_1_embedding, frase_4_embedding) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase 1 e Frase 2 0.16096973419189453\n",
            "Frase 1 e Frase 3 0.2234203815460205\n",
            "Frase 2 e Frase 3 0.2526938319206238\n",
            "Frase 1 e Frase 4 0.29043054580688477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZWHiGSZZnT"
      },
      "source": [
        "<b>Atividade </b>\n",
        "\n",
        "6) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsFFxOoeZZnU"
      },
      "source": [
        "Nesse caso, quanto menor a distância mais similar é uma frase da outra. Usando o Embedding podemos ver uma variabilidade muito maior dos resultados comparados aos outros métodos o que nos permite fazer uma análise melhor. De novo é possível confirmar a similaridade entre as frases 1 e 2 devido a menor distância, entretando a frase 4 por ser uma frase muito pequena ao compará-la com a frase 1, apesar de ambas serem positivas o valor da distância é o mais alto, logo são pouco similares.  Ao comparar as frases 1 e 3, e 2 e 3, apesar de serem um positiva e a outra negativa, acredito que como algumas palavras usadas nos dois contextos são próxima a distância do conseno não foi muito grande, impedido que fosse possível contatar que as opiniões expostas pelos usuários são divergentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5acLVhZZne"
      },
      "source": [
        "## WMD\n",
        "\n",
        "O WMD já está incorporado ao Word2Vec\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "7) Calcule a distância WMD e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: use a variável já tokenizada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0881q7vZZne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c6974359-5185-44b2-e29f-9fd6f366e55b"
      },
      "source": [
        "print (\"Frase 1 e Frase 2\",word_vectors.wmdistance(frase1_pre_processada, frase2_pre_processada) )\n",
        "print (\"Frase 1 e Frase 3\",word_vectors.wmdistance(frase1_pre_processada, frase3_pre_processada) )\n",
        "print (\"Frase 2 e Frase 3\",word_vectors.wmdistance(frase2_pre_processada, frase3_pre_processada) )\n",
        "print (\"Frase 1 e Frase 4\",word_vectors.wmdistance(frase1_pre_processada, frase3_pre_processada) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase 1 e Frase 2 3.0725697404938526\n",
            "Frase 1 e Frase 3 3.759219170455064\n",
            "Frase 2 e Frase 3 3.9048993635316385\n",
            "Frase 1 e Frase 4 3.759219170455064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsIENn25ZZni"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "8) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhC4OvGWZZnj"
      },
      "source": [
        "Avalianndo os valores vemos que as frases que deram mais próximas foram as frases 1 e 2, confirmando o mesmo que os outros métodos acima. A frase mais distante foi para o par de frases 2 e 3, esse método e o que permitiu visualizar uma distância maior entre essas duas frases confirmando a opinião divergente entre elas. Entretando, ao comparar as frases 2 e 3 apesar da distância ser maior indicando baixa similidade, não chega a ser tão expressiva se comparada à distancia entre as frases 1 e 3, mesmo essas tendo opiniões divergentes. Já como esperado, devido os resultados anteriores, como a frase 4 é muito curta impedi que ao calcular a distância o valor demostre a similiridade de sentido entre as frases 1 e 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXHGivtDZZnk"
      },
      "source": [
        "# Classificação de Documentos\n",
        "\n",
        "A clssificação de documentos é muito útil em vários aspectos. Um dos tipos de classificação de texto é a análise de sentimentos.\n",
        "\n",
        "A fim de ilustrar a classificação de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhCOoEn7ZZno"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "9) Carregue o dataset com o pandas e depois dê o head no dataframe.\n",
        "\n",
        "\n",
        "Link download: https://drive.google.com/open?id=15azJWdEEPGsXQGiDmEOseTBJcquWvBQc\n",
        "\n",
        "<b> Este dataset é sobre revisões de filmes do IMDB. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Boa59JNXCU"
      },
      "source": [
        "filepath = \"/content/drive/My Drive/imdb-reviews-pt-br.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI0oXiOoZZnp"
      },
      "source": [
        "df = pd.read_csv(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJYAOZecZZnv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "de5b3010-5bcf-4a32-caaa-a4b78ada61d3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... sentiment\n",
              "0   1  ...       neg\n",
              "1   2  ...       neg\n",
              "2   3  ...       neg\n",
              "3   4  ...       neg\n",
              "4   5  ...       neg\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKr5KPMZZnz"
      },
      "source": [
        "## Representação dos dados\n",
        "\n",
        "O sentimento positivo e negativo iremos binarizar cada um deles. Seja 1 positivo e 0 negativo.\n",
        "\n",
        "Iremos representar o texto de duas formas:\n",
        "\n",
        "- Bag of Words (BOW)\n",
        "- Embedding\n",
        "\n",
        "Depois iremos comparar o resultado de cada um deles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkSAiYMZZn0"
      },
      "source": [
        "### Representação Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0mYbWgcZZn1"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "10) Faça a representação dos sentimentos. 1 positivo; 0 negativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBkDjo4VZZn2"
      },
      "source": [
        "target = df[\"sentiment\"].replace([\"neg\", \"pos\"], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTjmqGvfO5E7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "dfe258bb-6f42-4b8b-992d-30ea509fb44e"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "49454    1\n",
              "49455    1\n",
              "49456    1\n",
              "49457    1\n",
              "49458    1\n",
              "Name: sentiment, Length: 49459, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8VgGgUnZZn8"
      },
      "source": [
        "### Bag of Words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirBWWCzZZn-"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "11) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuções\n",
        "- Mantenha o texto sem tokenização, ou seja uma string\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnJokm8VZZn-"
      },
      "source": [
        "def pre_processamento_texto_return_str(corpus):\n",
        "    #tokenizacao\"\n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "    #remove stopwords\n",
        "    portugues_stops = stopwords.words('portuguese')\n",
        "    corpus_alt = [t for t in corpus_alt if t not in portugues_stops]\n",
        "    #remove pontuação\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "    #lowercase  //Bárbara usei o Lowercase porque na aula você falou que você tinha esquecido de colocar\n",
        "    corpus_alt = [t.lower() for t in corpus_alt]\n",
        "\n",
        "    corpus_alt_str = ' '.join(corpus_alt)\n",
        "   \n",
        "    return corpus_alt_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeVPHlxtP938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "958a46f1f8284b7db48a7c12dcdd1784",
            "396829386459492697e2a76f7e932195",
            "2edba051ad534699973665399e5a325f",
            "455d5bfa4ae341ae93eb1cafa24207eb",
            "f9260b0758e242fc8c5bf5bbfd742561",
            "9d10383c312e465eab6ea68a40cd91fe",
            "6c25cdf2163c408593ebc2316a19ed52",
            "5aec3eb82ab64523ace67eab0e86ce5a"
          ]
        },
        "outputId": "5d802825-de91-4a0b-d905-df0a6c0240bd"
      },
      "source": [
        "df[\"text_pt_sem_stopwords\"] =  df[\"text_pt\"].progress_apply(lambda x: pre_processamento_texto_return_str(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "958a46f1f8284b7db48a7c12dcdd1784",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fTIEui7Qcu8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6edd4326-7aff-4210-92b1-81bee3266200"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_pt_sem_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "      <td>mais vez sr costner arrumou filme tempo necess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "      <td>este exemplo motivo maioria filmes ação mesmos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>nem beatles puderam escrever músicas todos gos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "      <td>filmes fotos latão palavra apropriada verdade ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                              text_pt_sem_stopwords\n",
              "0   1  ...  mais vez sr costner arrumou filme tempo necess...\n",
              "1   2  ...  este exemplo motivo maioria filmes ação mesmos...\n",
              "2   3  ...  primeiro tudo odeio raps imbecis poderiam agir...\n",
              "3   4  ...  nem beatles puderam escrever músicas todos gos...\n",
              "4   5  ...  filmes fotos latão palavra apropriada verdade ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TddT2Y6JZZoC"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "12) Aplique a representação do texto processado anteriormente com CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axSZo69tZZoC"
      },
      "source": [
        "docs_bag = vect_bag.fit_transform(df[\"text_pt_sem_stopwords\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKWTSraJRpMd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c0fa5f9-4ef7-40d1-bb6c-8566d98bb0b3"
      },
      "source": [
        "docs_bag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49459x129589 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 5308378 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mELsQ0tvZZoF"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSUe-Yr_ZZoG"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "13) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords_token``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Aplique lower\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuções\n",
        "- Mantenha o texto com tokenização\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJxB_SsZZoH"
      },
      "source": [
        "def pre_processamento_texto_return_token(corpus):\n",
        "    #tokenizacao\"\n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "    #lowcase\n",
        "    corpus_alt = [t.lower() for t in corpus_alt]\n",
        "    #remove stopwords\n",
        "    portugues_stops = stopwords.words('portuguese')\n",
        "    corpus_alt = [t for t in corpus_alt if t not in portugues_stops]\n",
        "    #remove pontuação\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "   \n",
        "    return corpus_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptgw58JzSe_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "374f5c43e51e4b0cad269568388dc8aa",
            "500a28ce756c43e6ba3784601716ff8b",
            "fb037533c9e44ad8bd4edbebdd15586c",
            "edd0523655fc4b53817fcbfc9160a8cb",
            "e5117b75e08240afa707ccf12b5f4200",
            "cdb80f5764bd4098a8b71be3320a2b76",
            "cf349b8892274da0b63cc513d8a81190",
            "d84ba189c2bd4badb59ad10d5c4abd79"
          ]
        },
        "outputId": "afa382bf-a72d-4735-a1d9-6758a2f90612"
      },
      "source": [
        "df[\"text_pt_sem_stopwords_token\"] =  df[\"text_pt\"].progress_apply(lambda x: pre_processamento_texto_return_token(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "374f5c43e51e4b0cad269568388dc8aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9zClDDES4rV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "bcbb7ecd-f766-4c04-84ff-2a6383c90aa1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_pt_sem_stopwords</th>\n",
              "      <th>text_pt_sem_stopwords_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "      <td>mais vez sr costner arrumou filme tempo necess...</td>\n",
              "      <td>[vez, sr, costner, arrumou, filme, tempo, nece...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "      <td>este exemplo motivo maioria filmes ação mesmos...</td>\n",
              "      <td>[exemplo, motivo, maioria, filmes, ação, mesmo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
              "      <td>[primeiro, tudo, odeio, raps, imbecis, poderia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>nem beatles puderam escrever músicas todos gos...</td>\n",
              "      <td>[beatles, puderam, escrever, músicas, todos, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "      <td>filmes fotos latão palavra apropriada verdade ...</td>\n",
              "      <td>[filmes, fotos, latão, palavra, apropriada, ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                        text_pt_sem_stopwords_token\n",
              "0   1  ...  [vez, sr, costner, arrumou, filme, tempo, nece...\n",
              "1   2  ...  [exemplo, motivo, maioria, filmes, ação, mesmo...\n",
              "2   3  ...  [primeiro, tudo, odeio, raps, imbecis, poderia...\n",
              "3   4  ...  [beatles, puderam, escrever, músicas, todos, g...\n",
              "4   5  ...  [filmes, fotos, latão, palavra, apropriada, ve...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPhMIrWZZoM"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "14) Aplique a representação do texto com Embeddings. Cada palavra tem um embedding, o embedding da frase é a média de todos embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gg0S5NZZoM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e08b555c080c4ce59db8d8cad44b2320",
            "02ba2b17bddd49d0a99bcb0c0a4e8023",
            "ec058f4655b94c72b853a9ca7a2d6c98",
            "091a06981f744042ade057243bc7dae3",
            "beb01e82803f4919a14a62e10a278063",
            "a37d04943278435f88d960b9f8deab79",
            "5e4a85941a1a45078ca17848e6ef3b25",
            "c23c9597eac6438e91456c3019e8a8f2"
          ]
        },
        "outputId": "311ba5ed-1a40-4e29-a950-a57bbbbd466b"
      },
      "source": [
        "X_embedding = df[\"text_pt_sem_stopwords_token\"].progress_apply(lambda x: get_embeddings(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e08b555c080c4ce59db8d8cad44b2320",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqPJf0yLZZoQ"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xhW7e2ZZoQ"
      },
      "source": [
        "### CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpcc167FZZoR"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "15) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "```python\n",
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3MeGchRZZoS"
      },
      "source": [
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(docs_bag, target,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ggm8ZLZZoY"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "16) Treine com uma regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJN8KMHiZZoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "aed35ac0-197f-4c5d-dd07-1d36946c0879"
      },
      "source": [
        "modelo_bow = LogisticRegression()\n",
        "modelo_bow.fit(X_train_bow, y_train_bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivlITfC2ZZof"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "17) Calcule as métricas de resultado utilizando método abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td_VQ4aCUFHi"
      },
      "source": [
        "y_pred=modelo_bow.predict(X_test_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4OOsg9uUK25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "987da429-bd05-48c1-c90a-748fe2520993"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfRxqjSZZog",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0fd25443-5819-4f7f-d9a0-6488d5b8b29a"
      },
      "source": [
        "print(classification_report(y_test_bow, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      6112\n",
            "           1       0.88      0.89      0.88      6253\n",
            "\n",
            "    accuracy                           0.88     12365\n",
            "   macro avg       0.88      0.88      0.88     12365\n",
            "weighted avg       0.88      0.88      0.88     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiulNTGNZZoj"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abN65iqZZok"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "18) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "Verifique o shape do X treino e X teste. Caso eles estejam com apenas uma dimensão, você precisa tranformá-los para duas dimensões, caso contrário ocorrerá erro no treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn57b04_ZZol"
      },
      "source": [
        "X_train_embedding, X_test_embedding, y_train_embedding, y_test_embedding = train_test_split(X_embedding.values, target,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5nr-3tgVNv6"
      },
      "source": [
        "X_train_embedding = pd.DataFrame([x for x in X_train_embedding])\n",
        "X_test_embedding = pd.DataFrame([x for x in X_test_embedding])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZc2wVBVUlRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "411af512-ad87-4df0-87df-681284637dbb"
      },
      "source": [
        "X_train_embedding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37094, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z7G-4A9VmVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "89774de5-1703-461d-a504-c89a140f951b"
      },
      "source": [
        "X_train_embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.164775</td>\n",
              "      <td>0.177243</td>\n",
              "      <td>-0.091046</td>\n",
              "      <td>-0.168941</td>\n",
              "      <td>-0.299286</td>\n",
              "      <td>-0.276219</td>\n",
              "      <td>0.068210</td>\n",
              "      <td>0.171216</td>\n",
              "      <td>-0.085756</td>\n",
              "      <td>0.352760</td>\n",
              "      <td>0.288270</td>\n",
              "      <td>-0.139173</td>\n",
              "      <td>-0.346397</td>\n",
              "      <td>0.028892</td>\n",
              "      <td>0.057119</td>\n",
              "      <td>0.085538</td>\n",
              "      <td>0.197978</td>\n",
              "      <td>-0.140617</td>\n",
              "      <td>0.182710</td>\n",
              "      <td>-0.234322</td>\n",
              "      <td>0.140444</td>\n",
              "      <td>0.197303</td>\n",
              "      <td>-0.259221</td>\n",
              "      <td>0.010419</td>\n",
              "      <td>-0.089338</td>\n",
              "      <td>-0.033548</td>\n",
              "      <td>-0.353268</td>\n",
              "      <td>-0.412356</td>\n",
              "      <td>-0.226751</td>\n",
              "      <td>0.188906</td>\n",
              "      <td>0.070062</td>\n",
              "      <td>0.130738</td>\n",
              "      <td>0.239321</td>\n",
              "      <td>0.258778</td>\n",
              "      <td>0.283559</td>\n",
              "      <td>-0.188337</td>\n",
              "      <td>0.146227</td>\n",
              "      <td>0.128092</td>\n",
              "      <td>0.214179</td>\n",
              "      <td>-0.285062</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430197</td>\n",
              "      <td>-0.290119</td>\n",
              "      <td>-0.310422</td>\n",
              "      <td>0.193344</td>\n",
              "      <td>0.077103</td>\n",
              "      <td>0.065438</td>\n",
              "      <td>-0.332814</td>\n",
              "      <td>0.143340</td>\n",
              "      <td>0.127281</td>\n",
              "      <td>-0.237968</td>\n",
              "      <td>-0.234810</td>\n",
              "      <td>0.105136</td>\n",
              "      <td>-0.279995</td>\n",
              "      <td>-0.376887</td>\n",
              "      <td>-0.051881</td>\n",
              "      <td>-0.108376</td>\n",
              "      <td>-0.237884</td>\n",
              "      <td>0.061548</td>\n",
              "      <td>-0.151421</td>\n",
              "      <td>-0.128395</td>\n",
              "      <td>0.064070</td>\n",
              "      <td>-0.294903</td>\n",
              "      <td>-0.159370</td>\n",
              "      <td>-0.147060</td>\n",
              "      <td>-0.311051</td>\n",
              "      <td>0.160057</td>\n",
              "      <td>0.123889</td>\n",
              "      <td>-0.262308</td>\n",
              "      <td>-0.056302</td>\n",
              "      <td>-0.216241</td>\n",
              "      <td>0.568133</td>\n",
              "      <td>-0.394102</td>\n",
              "      <td>-0.062824</td>\n",
              "      <td>-0.059671</td>\n",
              "      <td>0.165389</td>\n",
              "      <td>-0.146962</td>\n",
              "      <td>0.033940</td>\n",
              "      <td>0.135802</td>\n",
              "      <td>-0.148060</td>\n",
              "      <td>0.259065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.270804</td>\n",
              "      <td>0.055139</td>\n",
              "      <td>-0.072599</td>\n",
              "      <td>-0.117039</td>\n",
              "      <td>-0.194689</td>\n",
              "      <td>-0.306264</td>\n",
              "      <td>0.022104</td>\n",
              "      <td>0.162099</td>\n",
              "      <td>-0.070719</td>\n",
              "      <td>0.425425</td>\n",
              "      <td>0.156085</td>\n",
              "      <td>-0.145835</td>\n",
              "      <td>-0.376195</td>\n",
              "      <td>0.028109</td>\n",
              "      <td>0.033679</td>\n",
              "      <td>0.088126</td>\n",
              "      <td>0.232945</td>\n",
              "      <td>-0.093876</td>\n",
              "      <td>0.220061</td>\n",
              "      <td>-0.182259</td>\n",
              "      <td>0.106641</td>\n",
              "      <td>0.115869</td>\n",
              "      <td>-0.217178</td>\n",
              "      <td>-0.021485</td>\n",
              "      <td>-0.043441</td>\n",
              "      <td>0.018057</td>\n",
              "      <td>-0.215116</td>\n",
              "      <td>-0.254944</td>\n",
              "      <td>-0.226162</td>\n",
              "      <td>0.209804</td>\n",
              "      <td>0.102631</td>\n",
              "      <td>0.083512</td>\n",
              "      <td>0.252391</td>\n",
              "      <td>0.344627</td>\n",
              "      <td>0.199610</td>\n",
              "      <td>-0.250239</td>\n",
              "      <td>0.099688</td>\n",
              "      <td>0.171356</td>\n",
              "      <td>0.283941</td>\n",
              "      <td>-0.350958</td>\n",
              "      <td>...</td>\n",
              "      <td>0.420389</td>\n",
              "      <td>-0.253485</td>\n",
              "      <td>-0.258061</td>\n",
              "      <td>0.182879</td>\n",
              "      <td>0.053920</td>\n",
              "      <td>0.134684</td>\n",
              "      <td>-0.256869</td>\n",
              "      <td>0.056299</td>\n",
              "      <td>0.172810</td>\n",
              "      <td>-0.168708</td>\n",
              "      <td>-0.218559</td>\n",
              "      <td>0.124098</td>\n",
              "      <td>-0.277063</td>\n",
              "      <td>-0.511146</td>\n",
              "      <td>0.006866</td>\n",
              "      <td>-0.136825</td>\n",
              "      <td>-0.238070</td>\n",
              "      <td>0.080749</td>\n",
              "      <td>-0.154237</td>\n",
              "      <td>-0.142029</td>\n",
              "      <td>0.124534</td>\n",
              "      <td>-0.270540</td>\n",
              "      <td>-0.226084</td>\n",
              "      <td>-0.186330</td>\n",
              "      <td>-0.264603</td>\n",
              "      <td>0.165545</td>\n",
              "      <td>0.202721</td>\n",
              "      <td>-0.331068</td>\n",
              "      <td>-0.083111</td>\n",
              "      <td>-0.078711</td>\n",
              "      <td>0.596688</td>\n",
              "      <td>-0.338906</td>\n",
              "      <td>-0.142922</td>\n",
              "      <td>-0.177890</td>\n",
              "      <td>0.177174</td>\n",
              "      <td>-0.034758</td>\n",
              "      <td>-0.013745</td>\n",
              "      <td>0.047016</td>\n",
              "      <td>-0.156159</td>\n",
              "      <td>0.217429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.248587</td>\n",
              "      <td>0.192205</td>\n",
              "      <td>-0.037750</td>\n",
              "      <td>-0.144611</td>\n",
              "      <td>-0.249053</td>\n",
              "      <td>-0.260594</td>\n",
              "      <td>0.077630</td>\n",
              "      <td>0.221875</td>\n",
              "      <td>-0.067744</td>\n",
              "      <td>0.445615</td>\n",
              "      <td>0.218363</td>\n",
              "      <td>-0.142251</td>\n",
              "      <td>-0.370959</td>\n",
              "      <td>-0.038130</td>\n",
              "      <td>-0.013235</td>\n",
              "      <td>0.027577</td>\n",
              "      <td>0.204796</td>\n",
              "      <td>-0.195639</td>\n",
              "      <td>0.129604</td>\n",
              "      <td>-0.221722</td>\n",
              "      <td>0.105359</td>\n",
              "      <td>0.168186</td>\n",
              "      <td>-0.184282</td>\n",
              "      <td>-0.017558</td>\n",
              "      <td>-0.015111</td>\n",
              "      <td>0.021592</td>\n",
              "      <td>-0.358987</td>\n",
              "      <td>-0.315411</td>\n",
              "      <td>-0.187731</td>\n",
              "      <td>0.176140</td>\n",
              "      <td>0.004706</td>\n",
              "      <td>0.113213</td>\n",
              "      <td>0.211111</td>\n",
              "      <td>0.234917</td>\n",
              "      <td>0.239069</td>\n",
              "      <td>-0.210515</td>\n",
              "      <td>0.095759</td>\n",
              "      <td>0.197356</td>\n",
              "      <td>0.243410</td>\n",
              "      <td>-0.306429</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419168</td>\n",
              "      <td>-0.315818</td>\n",
              "      <td>-0.260172</td>\n",
              "      <td>0.257668</td>\n",
              "      <td>-0.080672</td>\n",
              "      <td>0.175380</td>\n",
              "      <td>-0.296332</td>\n",
              "      <td>0.092363</td>\n",
              "      <td>0.084530</td>\n",
              "      <td>-0.282227</td>\n",
              "      <td>-0.246190</td>\n",
              "      <td>0.102043</td>\n",
              "      <td>-0.220269</td>\n",
              "      <td>-0.334704</td>\n",
              "      <td>-0.076154</td>\n",
              "      <td>-0.063929</td>\n",
              "      <td>-0.245101</td>\n",
              "      <td>0.137309</td>\n",
              "      <td>-0.131172</td>\n",
              "      <td>-0.115422</td>\n",
              "      <td>0.089121</td>\n",
              "      <td>-0.240180</td>\n",
              "      <td>-0.146096</td>\n",
              "      <td>-0.171158</td>\n",
              "      <td>-0.265064</td>\n",
              "      <td>0.186290</td>\n",
              "      <td>0.114099</td>\n",
              "      <td>-0.247230</td>\n",
              "      <td>-0.147761</td>\n",
              "      <td>-0.133124</td>\n",
              "      <td>0.570264</td>\n",
              "      <td>-0.324722</td>\n",
              "      <td>-0.076872</td>\n",
              "      <td>-0.139255</td>\n",
              "      <td>0.251056</td>\n",
              "      <td>-0.134613</td>\n",
              "      <td>-0.022701</td>\n",
              "      <td>0.117389</td>\n",
              "      <td>-0.071973</td>\n",
              "      <td>0.282469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.208730</td>\n",
              "      <td>0.206336</td>\n",
              "      <td>-0.094195</td>\n",
              "      <td>-0.162718</td>\n",
              "      <td>-0.250112</td>\n",
              "      <td>-0.306295</td>\n",
              "      <td>0.063157</td>\n",
              "      <td>0.097309</td>\n",
              "      <td>-0.133926</td>\n",
              "      <td>0.386954</td>\n",
              "      <td>0.238586</td>\n",
              "      <td>-0.172071</td>\n",
              "      <td>-0.386691</td>\n",
              "      <td>0.010272</td>\n",
              "      <td>-0.010906</td>\n",
              "      <td>0.017958</td>\n",
              "      <td>0.184571</td>\n",
              "      <td>-0.155206</td>\n",
              "      <td>0.187456</td>\n",
              "      <td>-0.164736</td>\n",
              "      <td>0.077164</td>\n",
              "      <td>0.140951</td>\n",
              "      <td>-0.224388</td>\n",
              "      <td>0.016389</td>\n",
              "      <td>-0.005889</td>\n",
              "      <td>0.015916</td>\n",
              "      <td>-0.353920</td>\n",
              "      <td>-0.402255</td>\n",
              "      <td>-0.185143</td>\n",
              "      <td>0.259346</td>\n",
              "      <td>0.058873</td>\n",
              "      <td>0.163960</td>\n",
              "      <td>0.156002</td>\n",
              "      <td>0.268297</td>\n",
              "      <td>0.312440</td>\n",
              "      <td>-0.190172</td>\n",
              "      <td>0.087351</td>\n",
              "      <td>0.132719</td>\n",
              "      <td>0.218084</td>\n",
              "      <td>-0.256908</td>\n",
              "      <td>...</td>\n",
              "      <td>0.376571</td>\n",
              "      <td>-0.294111</td>\n",
              "      <td>-0.281558</td>\n",
              "      <td>0.220269</td>\n",
              "      <td>0.044552</td>\n",
              "      <td>0.136160</td>\n",
              "      <td>-0.294362</td>\n",
              "      <td>0.095797</td>\n",
              "      <td>0.155663</td>\n",
              "      <td>-0.316048</td>\n",
              "      <td>-0.226740</td>\n",
              "      <td>0.082501</td>\n",
              "      <td>-0.179877</td>\n",
              "      <td>-0.432484</td>\n",
              "      <td>-0.031216</td>\n",
              "      <td>-0.101213</td>\n",
              "      <td>-0.231649</td>\n",
              "      <td>0.057543</td>\n",
              "      <td>-0.171885</td>\n",
              "      <td>-0.054744</td>\n",
              "      <td>0.104736</td>\n",
              "      <td>-0.323152</td>\n",
              "      <td>-0.200952</td>\n",
              "      <td>-0.205490</td>\n",
              "      <td>-0.297817</td>\n",
              "      <td>0.112389</td>\n",
              "      <td>0.176066</td>\n",
              "      <td>-0.266190</td>\n",
              "      <td>-0.106083</td>\n",
              "      <td>-0.111462</td>\n",
              "      <td>0.606852</td>\n",
              "      <td>-0.345584</td>\n",
              "      <td>-0.089162</td>\n",
              "      <td>-0.056111</td>\n",
              "      <td>0.250674</td>\n",
              "      <td>-0.129950</td>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.114857</td>\n",
              "      <td>-0.085246</td>\n",
              "      <td>0.278568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.256833</td>\n",
              "      <td>0.204345</td>\n",
              "      <td>-0.081420</td>\n",
              "      <td>-0.148684</td>\n",
              "      <td>-0.332549</td>\n",
              "      <td>-0.304174</td>\n",
              "      <td>0.051899</td>\n",
              "      <td>0.154746</td>\n",
              "      <td>-0.113199</td>\n",
              "      <td>0.425564</td>\n",
              "      <td>0.274771</td>\n",
              "      <td>-0.186432</td>\n",
              "      <td>-0.420828</td>\n",
              "      <td>-0.050684</td>\n",
              "      <td>0.073438</td>\n",
              "      <td>0.034845</td>\n",
              "      <td>0.242141</td>\n",
              "      <td>-0.133862</td>\n",
              "      <td>0.128874</td>\n",
              "      <td>-0.173321</td>\n",
              "      <td>0.160880</td>\n",
              "      <td>0.168234</td>\n",
              "      <td>-0.228005</td>\n",
              "      <td>-0.022329</td>\n",
              "      <td>-0.041474</td>\n",
              "      <td>0.051025</td>\n",
              "      <td>-0.312522</td>\n",
              "      <td>-0.427488</td>\n",
              "      <td>-0.215221</td>\n",
              "      <td>0.235048</td>\n",
              "      <td>0.062051</td>\n",
              "      <td>0.134062</td>\n",
              "      <td>0.166536</td>\n",
              "      <td>0.193953</td>\n",
              "      <td>0.274553</td>\n",
              "      <td>-0.240456</td>\n",
              "      <td>0.203820</td>\n",
              "      <td>0.215730</td>\n",
              "      <td>0.208659</td>\n",
              "      <td>-0.282242</td>\n",
              "      <td>...</td>\n",
              "      <td>0.436772</td>\n",
              "      <td>-0.282662</td>\n",
              "      <td>-0.320882</td>\n",
              "      <td>0.180086</td>\n",
              "      <td>0.090267</td>\n",
              "      <td>0.113034</td>\n",
              "      <td>-0.337846</td>\n",
              "      <td>0.126446</td>\n",
              "      <td>0.192051</td>\n",
              "      <td>-0.213120</td>\n",
              "      <td>-0.226976</td>\n",
              "      <td>-0.023061</td>\n",
              "      <td>-0.199711</td>\n",
              "      <td>-0.376344</td>\n",
              "      <td>-0.070972</td>\n",
              "      <td>-0.082939</td>\n",
              "      <td>-0.201087</td>\n",
              "      <td>0.086647</td>\n",
              "      <td>-0.162449</td>\n",
              "      <td>-0.067839</td>\n",
              "      <td>0.106283</td>\n",
              "      <td>-0.285938</td>\n",
              "      <td>-0.164674</td>\n",
              "      <td>-0.120791</td>\n",
              "      <td>-0.322989</td>\n",
              "      <td>0.144510</td>\n",
              "      <td>0.127098</td>\n",
              "      <td>-0.252128</td>\n",
              "      <td>-0.058722</td>\n",
              "      <td>-0.217657</td>\n",
              "      <td>0.540956</td>\n",
              "      <td>-0.368099</td>\n",
              "      <td>-0.161087</td>\n",
              "      <td>-0.072898</td>\n",
              "      <td>0.229576</td>\n",
              "      <td>-0.184584</td>\n",
              "      <td>-0.002737</td>\n",
              "      <td>0.048413</td>\n",
              "      <td>-0.185809</td>\n",
              "      <td>0.320874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37089</th>\n",
              "      <td>0.283380</td>\n",
              "      <td>0.108041</td>\n",
              "      <td>-0.029679</td>\n",
              "      <td>-0.141522</td>\n",
              "      <td>-0.298804</td>\n",
              "      <td>-0.229321</td>\n",
              "      <td>0.069499</td>\n",
              "      <td>0.160524</td>\n",
              "      <td>-0.156123</td>\n",
              "      <td>0.430317</td>\n",
              "      <td>0.259402</td>\n",
              "      <td>-0.185385</td>\n",
              "      <td>-0.393033</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.026471</td>\n",
              "      <td>0.099585</td>\n",
              "      <td>0.228142</td>\n",
              "      <td>-0.136999</td>\n",
              "      <td>0.014190</td>\n",
              "      <td>-0.252917</td>\n",
              "      <td>0.092924</td>\n",
              "      <td>0.108140</td>\n",
              "      <td>-0.235887</td>\n",
              "      <td>-0.048901</td>\n",
              "      <td>0.025204</td>\n",
              "      <td>0.027919</td>\n",
              "      <td>-0.256203</td>\n",
              "      <td>-0.405055</td>\n",
              "      <td>-0.215271</td>\n",
              "      <td>0.258426</td>\n",
              "      <td>0.002466</td>\n",
              "      <td>-0.009720</td>\n",
              "      <td>0.113725</td>\n",
              "      <td>0.393803</td>\n",
              "      <td>0.143631</td>\n",
              "      <td>-0.248029</td>\n",
              "      <td>0.173845</td>\n",
              "      <td>0.069516</td>\n",
              "      <td>0.328380</td>\n",
              "      <td>-0.442306</td>\n",
              "      <td>...</td>\n",
              "      <td>0.418322</td>\n",
              "      <td>-0.234009</td>\n",
              "      <td>-0.266103</td>\n",
              "      <td>0.182480</td>\n",
              "      <td>-0.013978</td>\n",
              "      <td>0.026752</td>\n",
              "      <td>-0.280866</td>\n",
              "      <td>0.056698</td>\n",
              "      <td>0.147115</td>\n",
              "      <td>-0.215908</td>\n",
              "      <td>-0.156745</td>\n",
              "      <td>0.032462</td>\n",
              "      <td>-0.240778</td>\n",
              "      <td>-0.420357</td>\n",
              "      <td>-0.080457</td>\n",
              "      <td>-0.235118</td>\n",
              "      <td>-0.289816</td>\n",
              "      <td>0.029749</td>\n",
              "      <td>-0.110710</td>\n",
              "      <td>-0.083436</td>\n",
              "      <td>0.020155</td>\n",
              "      <td>-0.176222</td>\n",
              "      <td>-0.192184</td>\n",
              "      <td>-0.117615</td>\n",
              "      <td>-0.244836</td>\n",
              "      <td>0.176971</td>\n",
              "      <td>0.138432</td>\n",
              "      <td>-0.276746</td>\n",
              "      <td>-0.095664</td>\n",
              "      <td>-0.195586</td>\n",
              "      <td>0.534533</td>\n",
              "      <td>-0.369446</td>\n",
              "      <td>-0.047431</td>\n",
              "      <td>-0.172207</td>\n",
              "      <td>0.197534</td>\n",
              "      <td>-0.174676</td>\n",
              "      <td>0.012531</td>\n",
              "      <td>0.013552</td>\n",
              "      <td>-0.104310</td>\n",
              "      <td>0.272448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37090</th>\n",
              "      <td>0.212668</td>\n",
              "      <td>0.191068</td>\n",
              "      <td>-0.223002</td>\n",
              "      <td>-0.182821</td>\n",
              "      <td>-0.109953</td>\n",
              "      <td>-0.230212</td>\n",
              "      <td>0.043647</td>\n",
              "      <td>0.135049</td>\n",
              "      <td>-0.024267</td>\n",
              "      <td>0.365174</td>\n",
              "      <td>0.238840</td>\n",
              "      <td>-0.197789</td>\n",
              "      <td>-0.377867</td>\n",
              "      <td>-0.024632</td>\n",
              "      <td>0.034828</td>\n",
              "      <td>0.048900</td>\n",
              "      <td>0.194046</td>\n",
              "      <td>-0.228967</td>\n",
              "      <td>0.147607</td>\n",
              "      <td>-0.195168</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.076288</td>\n",
              "      <td>-0.265584</td>\n",
              "      <td>0.090123</td>\n",
              "      <td>-0.194016</td>\n",
              "      <td>-0.045416</td>\n",
              "      <td>-0.253095</td>\n",
              "      <td>-0.280754</td>\n",
              "      <td>-0.170021</td>\n",
              "      <td>0.304956</td>\n",
              "      <td>0.114612</td>\n",
              "      <td>0.039877</td>\n",
              "      <td>0.341023</td>\n",
              "      <td>0.428233</td>\n",
              "      <td>0.263305</td>\n",
              "      <td>-0.228651</td>\n",
              "      <td>0.130177</td>\n",
              "      <td>0.176572</td>\n",
              "      <td>0.272849</td>\n",
              "      <td>-0.297509</td>\n",
              "      <td>...</td>\n",
              "      <td>0.412430</td>\n",
              "      <td>-0.331319</td>\n",
              "      <td>-0.216865</td>\n",
              "      <td>0.259116</td>\n",
              "      <td>0.087228</td>\n",
              "      <td>-0.068100</td>\n",
              "      <td>-0.340640</td>\n",
              "      <td>0.158796</td>\n",
              "      <td>0.120758</td>\n",
              "      <td>-0.209512</td>\n",
              "      <td>-0.260937</td>\n",
              "      <td>0.202505</td>\n",
              "      <td>-0.262902</td>\n",
              "      <td>-0.405449</td>\n",
              "      <td>0.043909</td>\n",
              "      <td>-0.109186</td>\n",
              "      <td>-0.254663</td>\n",
              "      <td>0.081551</td>\n",
              "      <td>-0.086026</td>\n",
              "      <td>-0.030142</td>\n",
              "      <td>0.090546</td>\n",
              "      <td>-0.374068</td>\n",
              "      <td>-0.104768</td>\n",
              "      <td>-0.085728</td>\n",
              "      <td>-0.314119</td>\n",
              "      <td>0.183626</td>\n",
              "      <td>0.225435</td>\n",
              "      <td>-0.342618</td>\n",
              "      <td>-0.077428</td>\n",
              "      <td>-0.032321</td>\n",
              "      <td>0.516521</td>\n",
              "      <td>-0.402712</td>\n",
              "      <td>-0.187807</td>\n",
              "      <td>-0.086932</td>\n",
              "      <td>0.193121</td>\n",
              "      <td>-0.060391</td>\n",
              "      <td>-0.032361</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>-0.090937</td>\n",
              "      <td>0.278719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37091</th>\n",
              "      <td>0.180698</td>\n",
              "      <td>0.103384</td>\n",
              "      <td>-0.014254</td>\n",
              "      <td>-0.086892</td>\n",
              "      <td>-0.252935</td>\n",
              "      <td>-0.318607</td>\n",
              "      <td>0.042294</td>\n",
              "      <td>0.115469</td>\n",
              "      <td>-0.080932</td>\n",
              "      <td>0.399799</td>\n",
              "      <td>0.251260</td>\n",
              "      <td>-0.273341</td>\n",
              "      <td>-0.435297</td>\n",
              "      <td>-0.043178</td>\n",
              "      <td>-0.052093</td>\n",
              "      <td>0.019031</td>\n",
              "      <td>0.147340</td>\n",
              "      <td>-0.087913</td>\n",
              "      <td>0.135042</td>\n",
              "      <td>-0.052682</td>\n",
              "      <td>0.039058</td>\n",
              "      <td>0.171405</td>\n",
              "      <td>-0.271148</td>\n",
              "      <td>-0.054979</td>\n",
              "      <td>0.004248</td>\n",
              "      <td>0.011541</td>\n",
              "      <td>-0.400164</td>\n",
              "      <td>-0.441037</td>\n",
              "      <td>-0.169922</td>\n",
              "      <td>0.217697</td>\n",
              "      <td>-0.035962</td>\n",
              "      <td>0.021124</td>\n",
              "      <td>0.098754</td>\n",
              "      <td>0.323694</td>\n",
              "      <td>0.314408</td>\n",
              "      <td>-0.173612</td>\n",
              "      <td>0.115333</td>\n",
              "      <td>0.116378</td>\n",
              "      <td>0.284229</td>\n",
              "      <td>-0.259125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.405455</td>\n",
              "      <td>-0.269316</td>\n",
              "      <td>-0.256794</td>\n",
              "      <td>0.220107</td>\n",
              "      <td>0.041557</td>\n",
              "      <td>0.093148</td>\n",
              "      <td>-0.260041</td>\n",
              "      <td>0.003908</td>\n",
              "      <td>0.187343</td>\n",
              "      <td>-0.284705</td>\n",
              "      <td>-0.191810</td>\n",
              "      <td>0.046405</td>\n",
              "      <td>-0.158856</td>\n",
              "      <td>-0.523822</td>\n",
              "      <td>-0.121738</td>\n",
              "      <td>-0.079503</td>\n",
              "      <td>-0.255012</td>\n",
              "      <td>-0.009795</td>\n",
              "      <td>-0.212335</td>\n",
              "      <td>-0.106322</td>\n",
              "      <td>0.178715</td>\n",
              "      <td>-0.257489</td>\n",
              "      <td>-0.162975</td>\n",
              "      <td>-0.181352</td>\n",
              "      <td>-0.174290</td>\n",
              "      <td>0.109369</td>\n",
              "      <td>0.147432</td>\n",
              "      <td>-0.148118</td>\n",
              "      <td>-0.033698</td>\n",
              "      <td>-0.104722</td>\n",
              "      <td>0.717570</td>\n",
              "      <td>-0.308096</td>\n",
              "      <td>-0.066045</td>\n",
              "      <td>-0.139375</td>\n",
              "      <td>0.279215</td>\n",
              "      <td>-0.127438</td>\n",
              "      <td>0.038876</td>\n",
              "      <td>0.059436</td>\n",
              "      <td>-0.058780</td>\n",
              "      <td>0.270563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37092</th>\n",
              "      <td>0.221985</td>\n",
              "      <td>0.093702</td>\n",
              "      <td>-0.073643</td>\n",
              "      <td>-0.216875</td>\n",
              "      <td>-0.225598</td>\n",
              "      <td>-0.254632</td>\n",
              "      <td>0.008517</td>\n",
              "      <td>0.143648</td>\n",
              "      <td>-0.134123</td>\n",
              "      <td>0.450768</td>\n",
              "      <td>0.419030</td>\n",
              "      <td>-0.211132</td>\n",
              "      <td>-0.274162</td>\n",
              "      <td>0.076887</td>\n",
              "      <td>0.025070</td>\n",
              "      <td>0.080980</td>\n",
              "      <td>0.260977</td>\n",
              "      <td>-0.145138</td>\n",
              "      <td>0.222897</td>\n",
              "      <td>-0.165378</td>\n",
              "      <td>0.194462</td>\n",
              "      <td>0.127588</td>\n",
              "      <td>-0.098200</td>\n",
              "      <td>-0.036452</td>\n",
              "      <td>0.044178</td>\n",
              "      <td>-0.048542</td>\n",
              "      <td>-0.255908</td>\n",
              "      <td>-0.423242</td>\n",
              "      <td>-0.182588</td>\n",
              "      <td>0.179360</td>\n",
              "      <td>-0.019840</td>\n",
              "      <td>-0.017545</td>\n",
              "      <td>0.233543</td>\n",
              "      <td>0.390025</td>\n",
              "      <td>0.274690</td>\n",
              "      <td>-0.224052</td>\n",
              "      <td>0.166397</td>\n",
              "      <td>0.110332</td>\n",
              "      <td>0.322722</td>\n",
              "      <td>-0.247765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.363447</td>\n",
              "      <td>-0.152902</td>\n",
              "      <td>-0.313065</td>\n",
              "      <td>0.259700</td>\n",
              "      <td>0.041485</td>\n",
              "      <td>0.081048</td>\n",
              "      <td>-0.383283</td>\n",
              "      <td>0.052160</td>\n",
              "      <td>0.123007</td>\n",
              "      <td>-0.225077</td>\n",
              "      <td>-0.173925</td>\n",
              "      <td>0.076768</td>\n",
              "      <td>-0.257845</td>\n",
              "      <td>-0.441118</td>\n",
              "      <td>-0.081452</td>\n",
              "      <td>-0.131392</td>\n",
              "      <td>-0.238232</td>\n",
              "      <td>0.086202</td>\n",
              "      <td>-0.094827</td>\n",
              "      <td>-0.047772</td>\n",
              "      <td>0.140900</td>\n",
              "      <td>-0.215798</td>\n",
              "      <td>-0.247450</td>\n",
              "      <td>-0.112642</td>\n",
              "      <td>-0.351495</td>\n",
              "      <td>0.170460</td>\n",
              "      <td>0.250828</td>\n",
              "      <td>-0.322375</td>\n",
              "      <td>-0.087472</td>\n",
              "      <td>-0.162335</td>\n",
              "      <td>0.547232</td>\n",
              "      <td>-0.355882</td>\n",
              "      <td>-0.081172</td>\n",
              "      <td>-0.164445</td>\n",
              "      <td>0.132612</td>\n",
              "      <td>-0.196775</td>\n",
              "      <td>0.011455</td>\n",
              "      <td>0.100183</td>\n",
              "      <td>-0.236337</td>\n",
              "      <td>0.266202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37093</th>\n",
              "      <td>0.217830</td>\n",
              "      <td>0.168865</td>\n",
              "      <td>-0.038757</td>\n",
              "      <td>-0.170422</td>\n",
              "      <td>-0.119689</td>\n",
              "      <td>-0.228627</td>\n",
              "      <td>-0.049192</td>\n",
              "      <td>0.147708</td>\n",
              "      <td>-0.159200</td>\n",
              "      <td>0.346208</td>\n",
              "      <td>0.269503</td>\n",
              "      <td>-0.166754</td>\n",
              "      <td>-0.397346</td>\n",
              "      <td>-0.041311</td>\n",
              "      <td>0.016005</td>\n",
              "      <td>0.031943</td>\n",
              "      <td>0.321065</td>\n",
              "      <td>-0.119665</td>\n",
              "      <td>0.171241</td>\n",
              "      <td>-0.227765</td>\n",
              "      <td>0.154695</td>\n",
              "      <td>0.158668</td>\n",
              "      <td>-0.133686</td>\n",
              "      <td>0.059300</td>\n",
              "      <td>-0.039492</td>\n",
              "      <td>-0.007962</td>\n",
              "      <td>-0.105270</td>\n",
              "      <td>-0.393870</td>\n",
              "      <td>-0.159997</td>\n",
              "      <td>0.153865</td>\n",
              "      <td>0.020208</td>\n",
              "      <td>0.047503</td>\n",
              "      <td>0.282165</td>\n",
              "      <td>0.296949</td>\n",
              "      <td>0.168916</td>\n",
              "      <td>-0.149119</td>\n",
              "      <td>0.246803</td>\n",
              "      <td>0.261989</td>\n",
              "      <td>0.260746</td>\n",
              "      <td>-0.246500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388600</td>\n",
              "      <td>-0.107503</td>\n",
              "      <td>-0.256824</td>\n",
              "      <td>0.242089</td>\n",
              "      <td>0.066962</td>\n",
              "      <td>0.204662</td>\n",
              "      <td>-0.416143</td>\n",
              "      <td>0.220335</td>\n",
              "      <td>0.097876</td>\n",
              "      <td>-0.331097</td>\n",
              "      <td>-0.086365</td>\n",
              "      <td>0.101257</td>\n",
              "      <td>-0.241492</td>\n",
              "      <td>-0.418122</td>\n",
              "      <td>-0.044319</td>\n",
              "      <td>-0.103946</td>\n",
              "      <td>-0.130630</td>\n",
              "      <td>0.193581</td>\n",
              "      <td>-0.240192</td>\n",
              "      <td>-0.074186</td>\n",
              "      <td>0.085443</td>\n",
              "      <td>-0.210727</td>\n",
              "      <td>-0.165027</td>\n",
              "      <td>-0.141403</td>\n",
              "      <td>-0.353503</td>\n",
              "      <td>0.213343</td>\n",
              "      <td>0.160051</td>\n",
              "      <td>-0.252092</td>\n",
              "      <td>-0.112765</td>\n",
              "      <td>-0.132654</td>\n",
              "      <td>0.549235</td>\n",
              "      <td>-0.267770</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>-0.235151</td>\n",
              "      <td>0.140887</td>\n",
              "      <td>-0.090468</td>\n",
              "      <td>-0.043159</td>\n",
              "      <td>0.080841</td>\n",
              "      <td>-0.089286</td>\n",
              "      <td>0.253478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37094 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2   ...        97        98        99\n",
              "0      0.164775  0.177243 -0.091046  ...  0.135802 -0.148060  0.259065\n",
              "1      0.270804  0.055139 -0.072599  ...  0.047016 -0.156159  0.217429\n",
              "2      0.248587  0.192205 -0.037750  ...  0.117389 -0.071973  0.282469\n",
              "3      0.208730  0.206336 -0.094195  ...  0.114857 -0.085246  0.278568\n",
              "4      0.256833  0.204345 -0.081420  ...  0.048413 -0.185809  0.320874\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "37089  0.283380  0.108041 -0.029679  ...  0.013552 -0.104310  0.272448\n",
              "37090  0.212668  0.191068 -0.223002  ...  0.040482 -0.090937  0.278719\n",
              "37091  0.180698  0.103384 -0.014254  ...  0.059436 -0.058780  0.270563\n",
              "37092  0.221985  0.093702 -0.073643  ...  0.100183 -0.236337  0.266202\n",
              "37093  0.217830  0.168865 -0.038757  ...  0.080841 -0.089286  0.253478\n",
              "\n",
              "[37094 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9BR0H7fZZop"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "19) Treine com uma regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI29fY2ZZoq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ec2420a7-9653-42cf-f99e-25cf1f278005"
      },
      "source": [
        "modelo_embedding = LogisticRegression()\n",
        "modelo_embedding.fit(X_train_embedding, y_train_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvIYI1lJZZow"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "20) Calcule as métricas de resultado utilizando método abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFB32whZZox"
      },
      "source": [
        "#### Calcule as métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-dRYhR_ZZoy"
      },
      "source": [
        "y_pred=modelo_embedding.predict(X_test_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plHQhmWbWauo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f8cc95fd-a675-4753-e7fc-600fc10c8380"
      },
      "source": [
        "print(classification_report(y_test_embedding, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.77      6112\n",
            "           1       0.78      0.77      0.77      6253\n",
            "\n",
            "    accuracy                           0.77     12365\n",
            "   macro avg       0.77      0.77      0.77     12365\n",
            "weighted avg       0.77      0.77      0.77     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sp62Sb1ZZo1"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "21) Compare os resultados obtidos com o BagOfWords e com o Embedding. Explique os possíveis motivos desta diferença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RShZ0680ZZo2"
      },
      "source": [
        "O resultado deu muito diferente se comparar o BagOfWords com o Embedding, porque o Embedding usado durante essa prática foi muito pequeno apenas 100 dimensões, portanto, a quatidade de informação é muito pequena, ou seja, menos valores latentes, impactanto no resultado final. Então, seria necessário aumentar o número de features e as dimensões para melhorar o resultado do Embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-oH0GQfZZo3"
      },
      "source": [
        "# Análise de sentimentos\n",
        "\n",
        "O modelo que criamos anteriormente é para ilustrar como podemos realizar classificação de documentos.\n",
        "Quando a tarefa é sobre análise de sentimentos, temos duas opções: treinar nosso próprio modelo, como feito anteriormente ou utilizar uma das inúmeras ferramentas prontas.\n",
        "\n",
        "Vamos testar as seguintes ferramentas:\n",
        "\n",
        "- Vader\n",
        "- Textblob\n",
        "- Affin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilpNXE0cZZo3"
      },
      "source": [
        "Nesta atividade iremos utilizar as duas variáveis abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq0dLI9JZZo4"
      },
      "source": [
        "texto_neg = df.loc[0, \"text_en\"]\n",
        "texto_pos = df.loc[49431, \"text_en\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dB-FuBgZZo9"
      },
      "source": [
        "## Vader\n",
        "\n",
        "<b> Apenas Inglês </b>\n",
        "\n",
        "O VADER (Valence Aware Dictionary e sEntiment Reasoner) é uma ferramenta de análise de sentimentos baseada em regras e léxico, especificamente identifica os sentimentos expressos nas mídias sociais.\n",
        "\n",
        "- positive sentiment: compound score >= 0.05\n",
        "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
        "- negative sentiment: compound score <= -0.05\n",
        "\n",
        "Mais informações: https://github.com/cjhutto/vaderSentiment\n",
        "\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "22) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "analyzer.polarity_scores(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZE5KL-9ZZo9"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzsgloUpZZpB"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scYc7N8TYpyZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "220c9c12-97a1-4cd2-95d5-832e2bb7014b"
      },
      "source": [
        "analyzer.polarity_scores(texto_neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.3958, 'neg': 0.126, 'neu': 0.76, 'pos': 0.114}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdPqg7LNYtSH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "791b6871-7b79-43cd-ab96-8c1234c9c175"
      },
      "source": [
        "analyzer.polarity_scores(texto_pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.9969, 'neg': 0.084, 'neu': 0.737, 'pos': 0.179}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrJTCfKZZpE"
      },
      "source": [
        "## TextBlob\n",
        "\n",
        "<b> Apenas inglês </b>\n",
        "\n",
        "https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html\n",
        "\n",
        "<b> Atividade </b>\n",
        " \n",
        "23) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "sentence=TextBlob(texto)\n",
        "sentence.sentiment\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9IvBg5sZZpE"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-BV6UkOZZpJ"
      },
      "source": [
        "sentence=TextBlob(texto_neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9GCnZLRY3Og",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "466ab581-51d2-4057-efab-627331f51984"
      },
      "source": [
        "sentence.sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.06385964912280702, subjectivity=0.5629824561403508)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SOqGlL4Y43v"
      },
      "source": [
        "sentence=TextBlob(texto_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNKR4AUcY8CR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42ab9d6f-b130-4bf5-b084-c64e7c7499d2"
      },
      "source": [
        "sentence.sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.190819118692253, subjectivity=0.6026226012793177)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwk7dHuFZZpO"
      },
      "source": [
        "## Afinn\n",
        "\n",
        "- Valor maior que 0 indica sentimento positivo\n",
        "- Valor menor que 0 indica sentimento negativo\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "24) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "afinn = Afinn()\n",
        "afinn.score(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FS5AUsZZpP"
      },
      "source": [
        "from afinn import Afinn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF8E0CjzZZpX"
      },
      "source": [
        "afinn = Afinn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IgHHc3lY_qD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84f8946f-36e9-402b-c46d-2712233cc32b"
      },
      "source": [
        "afinn.score(texto_pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gub6GOttZCQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1f45543-c8bb-4d70-a559-bb688460ddfe"
      },
      "source": [
        "afinn.score(texto_neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhkDVIxZZpa"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "25) Para você, qual ferramenta teve melhor comportamento?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-w3CTXHZ4rY"
      },
      "source": [
        "O primeiro método VADER conseguiu identificar bem p texto positivo, entretanto falhou no texto negativo. O segundo método, TextBlob, varia entre -1 e 1 indo do mais negativo para o mais positivo para a polaridade, apesar de para o texto negativo o valor ser menor que para o texto positivo a diferença entre eles não chega a ser expressiva. O método Afinn acredito que foi o melhor, o valor para o texto positivo ficou alto e apesar do texto negativo não retornar um score negativo a distância entre as duas frases ficou relativamente grande se comparado aos outros métodos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWImUeS0ZZpb"
      },
      "source": [
        "# Dica:\n",
        "## Quando for trabalhar com um dataset em inglês, a biblioteca Spacy facilita!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONqxhviZZpc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "e076417f-bc21-43e2-e5e8-d62765ade68d"
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (46.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hj3KE97ZZph"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW0GLnhVZZpn"
      },
      "source": [
        "O scpay forne um pacote que já tem série de modelos já treinados em NLP. Inclusive para os embeddings em inglês.\n",
        "\n",
        "Para mais informações vá em:\n",
        "\n",
        "https://spacy.io/models/en#en_core_web_md\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v02Lid1QZZpo"
      },
      "source": [
        "Com o método abaixo carregamos um dos modelos do spacy:\n",
        "\n",
        "```python\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "```\n",
        "\n",
        "Para aplicar o modelo, basta passar o texto para o modelo carregado anteriormente:\n",
        "\n",
        "```python\n",
        "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
        "```\n",
        "\n",
        "Carregue o modelo e imprima doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRx4bZxZZpo"
      },
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDsD2THwZZps"
      },
      "source": [
        "doc = nlp(\"This is some text that I am processing with Spacy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWkp1tfZZpy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "724cb79e-01b6-40ca-eff1-d23ab45fd2e3"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "This is some text that I am processing with Spacy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vup3BXvmeX41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af78e64a-edf7-487f-b4f4-a3cb760c074a"
      },
      "source": [
        "# vetor da primeira palavra\n",
        "doc[0].vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-8.7595e-02,  3.5502e-01,  6.3868e-02,  2.9292e-01, -2.3635e-01,\n",
              "       -6.2773e-02, -1.6105e-01, -2.2842e-01,  4.1587e-02,  2.4844e+00,\n",
              "       -3.8217e-01,  3.2806e-02,  1.2348e-01, -1.8422e-03, -1.3848e-01,\n",
              "       -1.0005e-03, -4.3081e-02,  1.1659e+00, -4.7327e-02, -5.6004e-02,\n",
              "        1.5617e-01, -1.3394e-01,  2.3229e-01,  8.7602e-02, -3.2329e-01,\n",
              "        1.6721e-01, -1.6221e-01, -9.1919e-02, -3.8004e-01,  1.2686e-01,\n",
              "        6.7819e-02,  3.2509e-01, -5.7245e-02, -3.2630e-01, -1.1903e-01,\n",
              "       -6.3964e-04, -5.9275e-03, -2.9934e-01, -8.5043e-02, -2.6683e-01,\n",
              "       -1.5815e-01,  2.5963e-01,  2.2571e-01,  6.2582e-02, -1.9394e-01,\n",
              "        2.1922e-01, -3.1186e-01,  3.7084e-01, -3.6577e-01, -5.2483e-02,\n",
              "       -4.3101e-01,  1.2379e-01,  1.5529e-02, -1.2505e-01,  2.2327e-01,\n",
              "        2.9365e-01, -8.5104e-03, -8.3909e-02,  2.4078e-01, -3.4913e-01,\n",
              "       -2.8355e-01, -7.6594e-02, -1.7130e-01,  3.2869e-01,  2.9024e-01,\n",
              "       -6.2741e-02, -5.5278e-02, -2.8706e-01,  7.9608e-02,  1.3234e-01,\n",
              "        4.7857e-01,  1.9623e-01,  2.7314e-01, -1.3089e-01,  2.7630e-01,\n",
              "       -8.8846e-02, -1.2379e-01,  7.3987e-02, -5.1962e-01,  3.5227e-01,\n",
              "       -2.9182e-02,  1.6203e-01, -3.6908e-02,  2.8035e-01,  3.1739e-01,\n",
              "       -2.7597e-01, -4.3637e-01, -3.2842e-01,  3.6760e-01, -1.6278e-01,\n",
              "       -1.6278e-01,  3.7066e-01, -1.1340e-01,  3.0920e-01,  2.6133e-01,\n",
              "        3.9483e-01, -7.4612e-02, -2.2158e-01,  2.5172e-01,  2.9990e-01,\n",
              "        1.0566e-01, -1.1406e-01, -3.5395e-01,  6.6704e-02,  5.0216e-02,\n",
              "       -7.1479e-01,  9.8646e-02, -5.8832e-02, -4.7790e-03, -2.3920e-01,\n",
              "        1.0179e-01, -2.7205e-01,  1.6836e-01,  2.3420e-01, -3.7496e-01,\n",
              "        3.1125e-01, -3.1120e-01,  2.1778e-01,  3.0323e-01, -1.1729e-01,\n",
              "       -5.4639e-02, -1.5356e-01,  5.1771e-02, -1.1426e-01,  2.2473e-02,\n",
              "        4.4405e-02, -3.2101e-01, -2.7799e-01,  2.4675e-01, -1.1760e-01,\n",
              "       -1.5964e-02, -4.0969e-01, -2.6082e-01,  1.6021e-01,  6.1166e-02,\n",
              "       -3.1131e-03, -3.0573e-01, -4.1686e-02,  2.3524e-01, -5.8415e-02,\n",
              "       -1.6003e+00,  1.0126e-01,  1.2116e-01,  1.5319e-02, -1.1945e-01,\n",
              "       -3.9095e-01, -1.9919e-01,  4.3930e-02,  2.2886e-01, -5.3961e-02,\n",
              "       -2.6570e-02,  1.1952e-01,  1.8446e-01, -6.9963e-02,  3.6429e-01,\n",
              "       -2.3679e-02, -4.5081e-01, -3.7263e-02, -1.3243e-01, -1.1009e-01,\n",
              "       -1.5201e-01,  1.2182e-01, -9.3379e-02,  1.0215e-01, -3.4126e-01,\n",
              "       -7.8150e-02,  2.7685e-02, -4.8772e-03,  2.7281e-01, -1.1304e-01,\n",
              "        1.2470e-02,  2.7008e-01,  3.8885e-01, -2.3909e-01, -1.6375e-01,\n",
              "        1.9977e-02, -1.0628e-01,  5.5798e-02,  1.4127e-01,  4.6536e-01,\n",
              "       -3.3169e-01,  1.8308e-01,  2.9646e-01,  2.3906e-02,  3.2799e-01,\n",
              "       -5.3632e-01, -4.6895e-01, -1.7593e-02,  4.6805e-03, -9.6152e-02,\n",
              "       -1.2695e-01,  6.4099e-02, -2.9787e-01,  3.7799e-01,  4.4469e-01,\n",
              "        1.2248e-01,  7.6388e-02, -1.8102e-01, -1.1795e-02,  4.0090e-01,\n",
              "       -3.6967e-01, -2.4106e-01, -4.2252e-01,  2.1378e-01,  4.0977e-01,\n",
              "        1.3013e-01, -3.3478e-02,  9.3179e-03,  2.9553e-01,  6.8702e-02,\n",
              "       -1.4949e-01,  1.0473e-01,  3.8860e-01, -3.7063e-01, -6.8934e-02,\n",
              "        4.2111e-01,  1.0861e-01,  1.8585e-01, -1.1387e-01,  2.0370e-01,\n",
              "        9.4214e-02, -2.1426e-01, -1.9376e-01,  1.2261e-01,  1.3971e-01,\n",
              "       -5.4205e-01, -2.4502e-01,  4.7454e-01, -5.9380e-02, -1.2865e-01,\n",
              "       -1.7345e-01,  3.7465e-01, -7.2616e-02,  3.1124e-01, -3.3315e-04,\n",
              "       -3.1445e-03,  1.1435e-03, -8.0773e-02, -5.2824e-02,  2.6108e-01,\n",
              "        2.4586e-01, -5.8762e-02, -2.1999e-02,  1.4060e-01,  3.6004e-01,\n",
              "       -8.1521e-02, -2.8828e-02,  2.3878e-01, -1.2243e-01,  1.8758e-01,\n",
              "        6.9072e-02, -6.8685e-02,  1.2377e-01,  3.1713e-02, -1.1530e-01,\n",
              "        3.8205e-01,  4.8575e-01, -1.6466e-01,  1.1033e-01,  1.3873e-01,\n",
              "        3.2145e-01,  2.8014e-02, -5.4760e-02, -1.9438e-01, -1.5438e-02,\n",
              "       -5.6435e-02,  2.3037e-02,  4.2915e-01,  5.9080e-01,  9.6298e-02,\n",
              "        1.2788e-01,  1.5916e-01, -7.2056e-02, -2.1036e-01,  5.7346e-02,\n",
              "        4.5768e-02,  1.5730e-01,  3.1019e-01, -4.2692e-02,  1.7531e-02,\n",
              "        2.9585e-02, -4.2749e-02, -1.0006e-01, -3.1611e-01, -4.5054e-03,\n",
              "       -1.3689e-01,  4.0798e-01, -6.5866e-02,  2.0162e-01, -7.9660e-02,\n",
              "       -3.9495e-02,  9.3723e-02,  9.3557e-02, -9.7551e-02,  3.0639e-01,\n",
              "       -2.7325e-01, -3.3112e-01,  3.4460e-02, -1.5027e-01,  4.0673e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_lpJycEeagG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed27b7e8-33eb-468c-c457-04d7d13f53a5"
      },
      "source": [
        "doc.vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.36412969e-02,  2.79353321e-01, -1.05259977e-01, -1.76284965e-02,\n",
              "        1.34550199e-01,  1.92671806e-01,  5.50469756e-03, -2.39132687e-01,\n",
              "       -4.06342074e-02,  1.78010297e+00, -1.80772960e-01,  1.02661893e-01,\n",
              "        6.84069991e-02, -5.09319194e-02, -7.65837058e-02, -3.77540514e-02,\n",
              "        8.24129581e-03,  1.37752008e+00, -1.78934380e-01, -5.76109104e-02,\n",
              "        1.66338980e-02, -3.62196006e-02, -7.48579949e-02,  4.40651290e-02,\n",
              "       -2.65241470e-02,  2.41529979e-02,  9.79370065e-03, -1.13990309e-03,\n",
              "        1.59522101e-01, -1.56648397e-01, -9.12139937e-02,  9.11872908e-02,\n",
              "        1.07169405e-01, -1.08843103e-01, -7.94988051e-02, -4.74919155e-02,\n",
              "       -1.60613850e-01, -2.82304995e-02, -1.03425637e-01, -1.14933215e-01,\n",
              "        1.62531182e-01, -1.01342008e-01,  2.17013666e-03,  3.47881988e-02,\n",
              "       -6.34927005e-02,  2.44374484e-01, -3.01910043e-02, -1.46046979e-02,\n",
              "       -1.06488302e-01,  6.26319647e-03, -1.30655810e-01,  7.04905912e-02,\n",
              "       -4.86716032e-02,  3.78802009e-02,  8.03539976e-02,  6.92120939e-02,\n",
              "       -1.90451387e-02, -1.12328693e-01,  6.94227666e-02, -1.64191097e-01,\n",
              "       -1.31847098e-01, -1.49894238e-01, -1.36391714e-01,  1.40043885e-01,\n",
              "       -9.31040943e-03, -2.03303784e-01,  9.60722417e-02,  2.30206400e-01,\n",
              "        2.50716810e-03,  2.02762410e-01,  4.17191163e-02,  3.99811044e-02,\n",
              "        1.92619696e-01, -1.40993387e-01,  1.25155553e-01, -1.58516970e-02,\n",
              "        1.09475099e-01, -7.27410093e-02, -2.68682182e-01,  2.30902284e-01,\n",
              "        2.34210819e-01,  1.11316703e-01, -9.12195072e-02, -2.42443047e-02,\n",
              "        1.42992407e-01, -2.19214275e-01,  4.11447994e-02, -2.86822319e-01,\n",
              "        2.63879955e-01, -5.77340014e-02, -1.64064974e-01, -2.05429066e-02,\n",
              "       -1.22913897e-01,  1.18417896e-01,  1.84989497e-01,  1.00361109e-01,\n",
              "        9.49232131e-02,  6.60311952e-02, -9.33668986e-02, -1.59936994e-02,\n",
              "       -2.31165010e-02, -6.52898028e-02, -1.23388097e-01, -4.01628986e-02,\n",
              "        1.45462602e-01, -8.75642002e-01,  9.09521952e-02, -5.13979010e-02,\n",
              "        7.28402957e-02, -1.27135485e-01, -1.40351206e-01, -2.07270592e-01,\n",
              "        4.01909929e-03, -7.35395998e-02, -9.45103019e-02,  1.21432200e-01,\n",
              "       -1.18193254e-01,  1.45202488e-01,  1.25529768e-03, -2.94554029e-02,\n",
              "       -4.62799985e-03, -9.12842974e-02,  5.74196987e-02,  6.77531958e-02,\n",
              "        1.48049906e-01,  1.29439309e-01, -1.82068050e-02, -2.13463187e-01,\n",
              "        1.48183014e-02, -2.44854987e-02,  4.59263101e-02, -9.94249955e-02,\n",
              "       -2.04361603e-01,  1.12105906e-01,  1.94074497e-01, -7.32466131e-02,\n",
              "       -4.93362956e-02,  6.62797887e-04,  5.34777045e-02, -9.54100639e-02,\n",
              "       -1.28930104e+00,  8.45059007e-02,  1.24973014e-01, -3.43775041e-02,\n",
              "        5.58522530e-02, -1.11490890e-01, -8.01380053e-02, -7.85033032e-02,\n",
              "        7.36995935e-02, -2.37317413e-01, -8.74600112e-02, -6.93827048e-02,\n",
              "        4.13617417e-02,  7.55745023e-02, -4.00402024e-03,  2.58650188e-03,\n",
              "       -1.34799585e-01, -1.64788991e-01, -1.63010061e-02,  8.57740361e-03,\n",
              "       -6.23569898e-02, -9.51829739e-03,  2.04498690e-04, -4.45383005e-02,\n",
              "       -2.48028159e-01, -8.60313028e-02, -5.29805943e-02, -7.82409310e-02,\n",
              "        1.80566125e-02, -1.05987206e-01, -1.14582300e-01,  3.88075039e-02,\n",
              "        4.69984934e-02, -1.76031515e-01,  3.83771993e-02,  2.42205989e-02,\n",
              "       -9.93327945e-02, -7.79675990e-02,  5.88746071e-02,  1.01415277e-01,\n",
              "       -2.67262999e-02, -8.07069987e-02, -1.39405075e-02, -6.47260174e-02,\n",
              "        1.52794840e-02, -3.01251654e-02, -1.49534196e-01, -5.98808043e-02,\n",
              "        2.09884485e-03, -1.24438748e-01,  3.57211009e-02, -6.95929816e-03,\n",
              "       -1.68785602e-01,  7.65989721e-03,  9.05171037e-02,  3.18026006e-01,\n",
              "       -6.16580024e-02, -1.26068696e-01, -8.25089961e-02,  5.57253957e-02,\n",
              "       -8.41946006e-02, -1.90070719e-01, -1.62521005e-03, -6.82969540e-02,\n",
              "        2.41109580e-01,  4.19945940e-02, -1.37534011e-02,  8.93083215e-02,\n",
              "        1.09719690e-02,  3.18845995e-02, -1.14059210e-01,  4.48014028e-02,\n",
              "        4.13361900e-02, -2.82665312e-01, -9.96703953e-02,  1.46997511e-01,\n",
              "       -4.94053029e-02,  3.08074001e-02, -2.00760528e-01,  9.90296379e-02,\n",
              "        3.79908979e-02,  4.67142351e-02,  4.77707013e-02,  1.34153992e-01,\n",
              "       -5.08050108e-03,  4.39774953e-02,  7.36405998e-02,  1.02516197e-01,\n",
              "        1.28911704e-01, -4.55930941e-02, -1.20674014e-01,  2.43296027e-02,\n",
              "       -3.02500520e-02,  1.66422293e-01, -7.97684118e-02, -5.26273735e-02,\n",
              "       -1.23622812e-01,  4.27368023e-02, -6.21971004e-02,  1.25764996e-01,\n",
              "        1.84183091e-01,  1.07203998e-01, -2.95391623e-02,  1.42826796e-01,\n",
              "        1.09824881e-01, -1.99228719e-01, -1.49215404e-02, -2.23988891e-01,\n",
              "        1.06461301e-01,  7.05484003e-02,  6.54515028e-02, -1.27890497e-01,\n",
              "        3.23300287e-02,  7.33296275e-02,  1.88077211e-01,  1.18194893e-01,\n",
              "        8.73716325e-02, -7.22722933e-02,  5.59383444e-02,  6.47740066e-03,\n",
              "        2.00715184e-01,  9.62314978e-02, -3.48809664e-03,  2.75218002e-02,\n",
              "        2.66793407e-02, -4.74142991e-02, -6.72583003e-03,  6.16225004e-02,\n",
              "        6.77095532e-01, -2.60432009e-02, -5.73220849e-02, -1.32674202e-01,\n",
              "       -1.45575196e-01, -2.10457489e-01,  5.04911169e-02,  3.34890969e-02,\n",
              "        1.69010018e-03,  7.47893304e-02,  1.15959838e-01,  1.70419499e-01,\n",
              "        2.78796494e-01,  6.95598137e-04,  1.38465315e-01, -1.39558002e-01,\n",
              "       -1.05340723e-02, -3.17818001e-02,  1.44083828e-01,  1.84036009e-02,\n",
              "        7.65393823e-02, -1.08156681e-01, -1.86349601e-01, -1.51499901e-02,\n",
              "       -2.16642022e-02, -4.31120396e-03,  8.77634883e-02, -6.35844022e-02,\n",
              "       -1.29146904e-01, -2.63259001e-02, -1.46536082e-01,  2.72397280e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuqCJaIMZZp3"
      },
      "source": [
        "Ao aplicar o modelo carregado a variável <b> doc </b> já possui os embeddings de cada uma das palavras e o embedding da frase, que é a média de todos vetores de todas palavras.\n",
        "\n",
        "```python\n",
        "#vetor da primeira palavra\n",
        "doc[0].vector\n",
        "#vetor agregado pela média - embedding do documento\n",
        "doc.vector\n",
        "```\n",
        "O código abaixo mostra que a média de uma posição em específico dos embeddings de todas as palavras e a posição do embedding do documento possuem o mesmo valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r426C5mvZZp4"
      },
      "source": [
        "def calcula_media_posicao(x):\n",
        "    soma = 0\n",
        "    vector = []\n",
        "    for i in range(0,len(doc)):\n",
        "        vector.append(doc[i].vector)    \n",
        "    \n",
        "    for v in vector:\n",
        "        soma += v[x]\n",
        "    return soma/len(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "969rVBBYZZp8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c583aec9-1107-4c0b-fcc5-9166dabd68cb"
      },
      "source": [
        "round(calcula_media_posicao(10),6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.180773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmkeEtyQZZqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09389dba-af0c-4027-84f6-dbcce7f5981c"
      },
      "source": [
        "round(doc.vector[10], 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.180773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}